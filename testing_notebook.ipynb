{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Imports\n",
    "from CircuitCollection import CircuitCollection as cc\n",
    "from CircuitCollection import CircuitDataset as cd\n",
    "from model.Environments import CutEnvironment\n",
    "import model.Utils as utils\n",
    "import model.ActorCritic as models\n",
    "\n",
    "# Qiskit Imports\n",
    "from qiskit import *\n",
    "from qiskit.transpiler import CouplingMap\n",
    "from qiskit.tools.jupyter import *\n",
    "from qiskit.visualization import *\n",
    "\n",
    "# Other Imports\n",
    "import itertools\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Representation\n",
    "Other works (like [this](https://iopscience.iop.org/article/10.1088/2632-2153/ac28dd)) use an \"image\" based representation. I will use a similar one.\n",
    "* each gate will be one column of \"pixels\"\n",
    "* 1 indicates that the corresponding qubit is involved with the gate, 0 means that there are no gates on that qubit           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Circuit Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Run this to generate new circuit collection\n",
    "#####################\n",
    "filename = \"./data/4_qubits_2_depth_10_trials.p\" # file to save circuit collection to\n",
    "\n",
    "# start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize a 4 qubit circuit\n",
    "n = 4\n",
    "depth = 2\n",
    "trials = 10\n",
    "gates = [(0, 1), (1, 2), (2, 3), (0, 2), (1, 3), (0, 3)] # full gateset of cnots\n",
    "\n",
    "# circuit collection\n",
    "circol = cc(gates, n, depth)\n",
    "\n",
    "# generate all children\n",
    "circol.generate_circuits()\n",
    "\n",
    "# build all circuits\n",
    "circol.build_circuits()\n",
    "\n",
    "# transpile all circuits\n",
    "circol.transpile_circuits(n = 20, trials = trials, coupling_map = CouplingMap.from_line(n), optimization_level=1)\n",
    "\n",
    "# print run time\n",
    "print(\"--- Total: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# print circuits per second\n",
    "print(\"--- %s circuits per second ---\" % (circol.num_circuits() * trials/(time.time() - start_time)))\n",
    "\n",
    "pickle.dump(circol, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Run this to load a previously generated circuit collection\n",
    "#####################\n",
    "filename = \"../../qcircml_code/data/circol_test.p\" # file to load circuit collection \n",
    "\n",
    "# load circuit collection\n",
    "circol = pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "# retrieve parameters\n",
    "n = circol.num_qubits\n",
    "depth = circol.depth\n",
    "\n",
    "# print parameters\n",
    "print(\"Circuit Collection Paramters:\")\n",
    "print(\"n = \" + str(n))\n",
    "print(\"depth = \" + str(depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Best Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute best cut for each circuit\n",
    "\n",
    "optimal_circuits = []\n",
    "optimal_cuts = []\n",
    "\n",
    "for j in range(len(circol.circuits[-1])): # loop through max lenght circuits\n",
    "    ind = circol.child_indecies(len(circol.circuits) - 1, j) # compute children indecies\n",
    "    depths = [circol.q_transpiled[n1][n2].depth() for n1, n2 in ind]\n",
    "    min = depths[np.argmin(depths)]\n",
    "    min_indexes = np.where(np.array(depths) == min)[0]\n",
    "\n",
    "    optimal_circuits.append([ind[i] for i in min_indexes]) # choose child with lowest depth\n",
    "\n",
    "    # compute the index of the cut gate\n",
    "    parent_gates = circol.circuits[-1][j]\n",
    "    child_gates = [circol.circuits[optimal_circuits[-1][i][0]][optimal_circuits[-1][i][1]] for i in range(len(optimal_circuits[-1]))]\n",
    "\n",
    "    temp = []\n",
    "    for gate in parent_gates:\n",
    "        b = False\n",
    "\n",
    "        # check if gate is a best cut\n",
    "        for child_list in child_gates:\n",
    "            if gate not in child_list:\n",
    "                b = True\n",
    "                break\n",
    "\n",
    "        if b:\n",
    "            temp.append(parent_gates.index(gate))\n",
    "        \n",
    "    optimal_cuts.append(temp)\n",
    "\n",
    "# draw a random circuit with the optimal cut\n",
    "print()\n",
    "print(optimal_cuts)\n",
    "\n",
    "test = 8\n",
    "n1, n2 = optimal_circuits[test]\n",
    "print(circol.q_transpiled[-1][test].draw())\n",
    "print(circol.q_transpiled[n1][n2].draw())\n",
    "print(f\"Depth difference: {-circol.q_transpiled[n1][n2].depth() + circol.q_transpiled[-1][test].depth()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-danger\"> FIXME: add some statistics </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-danger\"> FIXME: https://ekamperi.github.io/machine%20learning/2021/01/13/python-decorators-and-tf-function.html </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of Actor-Critic \n",
    "* https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic\n",
    "* https://arshren.medium.com/unlocking-the-secrets-of-actor-critic-reinforcement-learning-a-beginners-guide-3c5953b13551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load circuit collection\n",
    "circol = pickle.load(open(\"../qcircml_code/data/circol_test.p\", \"rb\"))\n",
    "\n",
    "# generate images\n",
    "circol.convert_to_images()\n",
    "\n",
    "circol = pickle.dump(circol, open(\"../qcircml_code/data/circol_test.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason adding the tf.function decorator causes the model to not converge (does no better than random)\n",
    "* this is likely due to the face that the tf.function generator compiles the code into a graph which does not allow for the random number generator to be used properly\n",
    "* it could also be due to some parameters not changing properly during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ../qcircml_code/logs/ --host=127.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([0] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.ActorCritic import CutterPointer, Attention\n",
    "import tensorflow as tf\n",
    "\n",
    "# testing attention layer\n",
    "att = Attention(100)\n",
    "\n",
    "batch_size = 16\n",
    "num_gates = 5\n",
    "lstm_width = 24\n",
    "x = tf.random.uniform((batch_size, num_gates, lstm_width))\n",
    "g = tf.random.uniform((batch_size, lstm_width))\n",
    "\n",
    "print(att(x, g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.Utils import compute_best_cuts\n",
    "from CircuitCollection import CircuitCollection as cc\n",
    "import pickle\n",
    "\n",
    "circol = pickle.load(open(\"../../qcircml_code/data/circol_base_4qubits_8gates_depth3_dict.p\", \"rb\"))\n",
    "print(circol.depth)\n",
    "compute_best_cuts(circol, circol.depth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "in_t = tf.RaggedTensor.from_row_lengths(values=[1, 2, 3, 4, 5, 6], row_lengths = [1, 3, 2])\n",
    "a = tf.RaggedTensor.from_row_lengths(values=in_t, row_lengths = [2, 1])\n",
    "\n",
    "print(a)\n",
    "\n",
    "b = tf.gather(a, [1, 0])\n",
    "\n",
    "print(b)\n",
    "\n",
    "c = tf.gather_nd(b, [[1, 1], [0, 0]])\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Circuit Dataset Structure with Utils and Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../qcircml_code/data/circset_4qubits_7gates_depth3/section_0.p\n",
      "../../qcircml_code/data/circset_4qubits_7gates_depth3/section_1.p\n"
     ]
    }
   ],
   "source": [
    "# load circuit dataset\n",
    "root_dir = \"../../qcircml_code/data/circset_4qubits_7gates_depth3\"\n",
    "circol = pickle.load(open(root_dir + \"/dataset.p\", \"rb\"))\n",
    "\n",
    "# instantiate environment\n",
    "env = CutEnvironment(circuit_dataset = circol)\n",
    "\n",
    "# create iterator\n",
    "iterator = iter(env.circol)\n",
    "\n",
    "num = len(env.circol.current_section.train_batches)\n",
    "\n",
    "first = env.circol.current_section.pickle_file\n",
    "print(first)\n",
    "\n",
    "# get batches\n",
    "for i in range(41):\n",
    "    batch = next(iterator)[0:2]\n",
    "\n",
    "second = env.circol.current_section.pickle_file\n",
    "print(second)\n",
    "\n",
    "batch_t = tf.convert_to_tensor(batch, dtype=tf.int32)\n",
    "\n",
    "\n",
    "######## Environment Testing #########\n",
    "\n",
    "# test convert to images\n",
    "images = env.convert_to_images_c(batch_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0],\n",
      "  [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0],\n",
      "  [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
      "  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]],\n",
      "\n",
      " [[1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0],\n",
      "  [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0],\n",
      "  [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0],\n",
      "  [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]]]>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "TypeError: object of type 'RaggedTensor' has no len()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# image = images[0]\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# print(image)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# image_t = tf.convert_to_tensor(np.transpose(imagenumpy))\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# print(image_t)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(images)\n\u001b[0;32m---> 12\u001b[0m \u001b[39mprint\u001b[39m(tf\u001b[39m.\u001b[39;49mconvert_to_tensor(images))\n",
      "File \u001b[0;32m~/.virtualenvs/qcircml/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.virtualenvs/qcircml/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: TypeError: object of type 'RaggedTensor' has no len()\n"
     ]
    }
   ],
   "source": [
    "# image = images[0]\n",
    "# print(image)\n",
    "\n",
    "# imagenumpy = image.numpy()\n",
    "# print(image.numpy())\n",
    "\n",
    "# image_t = tf.convert_to_tensor(np.transpose(imagenumpy))\n",
    "# print(image_t)\n",
    "\n",
    "print(images)\n",
    "\n",
    "print(images.to_tensor())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qcircml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
